{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Greedy_Epsilon_BERNOULI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLs2YXgWKMq0n5nY6qwamh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/Bayesian_AB_Testing/blob/main/Greedy_Epsilon_BERNOULI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZIhdr-okpKB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKSqDz3ooDe6"
      },
      "source": [
        "# Initalize constant\n",
        "NUM_TRIALS = 10000\n",
        "EPS = 0.1\n",
        "\n",
        "\n",
        "# True win rates of bandits or prboabiilties of bandits\n",
        "BANDIT_PROBABILITIES = [0.2, 0.5, 0.75]   "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPKDwd0Pol8d"
      },
      "source": [
        "## Epsilon-Greedy Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r1ycDlPofAu"
      },
      "source": [
        "\n",
        "class BanditArm:\n",
        "  def __init__(self, p):\n",
        "    # p: the win rate\n",
        "    self.p = p\n",
        "    self.p_estimate = 0\n",
        "    self.N = 0\n",
        "  \n",
        "  def pull(self):\n",
        "    # draw a 1 with probability p\n",
        "    return np.random.random() < self.p\n",
        "\n",
        "  def update(self, x):\n",
        "    self.N +=  1 # NUMBER OF SAMPLE COLLECTED\n",
        "    self.p_estimate = ((self.N - 1)* self.p_estimate    + x)/ self.N\n",
        "    #self.p_estimate = self.p_estimate + (( x - self.p_estimate )/ self.N)\n",
        "\n",
        "  def __str__(self) :\n",
        "    return \"This is my bandit class\"\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bandits = [BanditArm(p) for p in BANDIT_PROBABILITIES]\n",
        "print(len(bandits))\n",
        "b = bandits[0]\n",
        "print()\n",
        "print(b)"
      ],
      "metadata": {
        "id": "vXEvjCzLMu3v",
        "outputId": "f707f834-9c36-4d86-8605-c741779d3fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "\n",
            "This is my bandit class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = [b.p for b in bandits]\n",
        "y"
      ],
      "metadata": {
        "id": "99nLJlPcM1dq",
        "outputId": "8bff6935-a4e8-4fda-bfa5-6aba68c12a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.5, 0.75]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y)"
      ],
      "metadata": {
        "id": "DGmip1aONS1z",
        "outputId": "5f7f0aa4-0eea-42db-fb30-4f2061587a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "UpT_JZIYtT41",
        "outputId": "6702c732-5342-41cc-a077-9ad112136343"
      },
      "source": [
        "def experiment():\n",
        "  bandits = [BanditArm(p) for p in BANDIT_PROBABILITIES]\n",
        "\n",
        "  rewards = np.zeros(NUM_TRIALS)\n",
        "  num_times_explored = 0\n",
        "  num_times_exploited = 0\n",
        "  num_optimal = 0\n",
        "  optimal_j = np.argmax([b.p for b in bandits]) # WILL NOT E KNOWN IN REAL LIFE\n",
        "  print(\"optimal j:\", optimal_j)\n",
        "\n",
        "  for i in range(NUM_TRIALS):\n",
        "\n",
        "    # use epsilon-greedy to select the next bandit\n",
        "    if np.random.random() < EPS:\n",
        "      num_times_explored += 1\n",
        "      j = np.random.randint(len(bandits))\n",
        "\n",
        "    else:\n",
        "      num_times_exploited += 1\n",
        "      j = np.argmax([b.p_estimate for b in bandits])\n",
        "\n",
        "    # Will not be known in real life\n",
        "    if j == optimal_j:\n",
        "      num_optimal += 1\n",
        "\n",
        "    # pull the arm for the bandit with the largest sample\n",
        "    x = bandits[j].pull()\n",
        "\n",
        "    # update rewards log\n",
        "    rewards[i] = x\n",
        "\n",
        "    # update the distribution for the bandit whose arm we just pulled\n",
        "    bandits[j].update(x)\n",
        " \n",
        "  # print mean estimates for each bandit\n",
        "  for b in bandits:\n",
        "    print(\"mean estimate:\", b.p_estimate)\n",
        "\n",
        "  # print total reward\n",
        "  print(\"total reward earned:\", rewards.sum())\n",
        "  print(\"overall win rate:\", rewards.sum() / NUM_TRIALS)\n",
        "  print(\"num_times_explored:\", num_times_explored)\n",
        "  print(\"num_times_exploited:\", num_times_exploited)\n",
        "  print(\"num times selected optimal bandit:\", num_optimal)\n",
        "\n",
        "  # plot the results\n",
        "  cumulative_rewards = np.cumsum(rewards)\n",
        "  win_rates = cumulative_rewards / (np.arange(NUM_TRIALS) + 1)\n",
        "  plt.plot(win_rates,label = 'experiment')\n",
        "  plt.plot(np.ones(NUM_TRIALS)*np.max(BANDIT_PROBABILITIES), label = 'real-life')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  experiment() \n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal j: 2\n",
            "mean estimate: 0.18362282878411917\n",
            "mean estimate: 0.49710982658959535\n",
            "mean estimate: 0.7541887363528241\n",
            "total reward earned: 7223.0\n",
            "overall win rate: 0.7223\n",
            "num_times_explored: 993\n",
            "num_times_exploited: 9007\n",
            "num times selected optimal bandit: 9251\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding cooling schedules"
      ],
      "metadata": {
        "id": "9zHZl5iiK9sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize constant\n",
        "NUM_TRIALS = 10000\n",
        "e_0 = 0.1\n",
        "k   = 0.1\n",
        "alpha = 0.1\n",
        "a = 0.1\n",
        "b = 0.1\n",
        "c = 0.04\n",
        "e_min = 0.08\n",
        "\n",
        "# True win rates of bandits or prboabiilties of bandits\n",
        "BANDIT_PROBABILITIES = [0.2, 0.5, 0.75]   "
      ],
      "metadata": {
        "id": "KDE1MLNGLAc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epsilon-Greedy Algorithm with cooling schedules incorpoated"
      ],
      "metadata": {
        "id": "DnmbOQZbLHR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BanditArm:\n",
        "  def __init__(self, p,e_0):\n",
        "    # p: the win rate\n",
        "    self.p = p\n",
        "    self.p_estimate = 0\n",
        "    self.N = 0\n",
        "    self.EPS = e_0\n",
        "\n",
        "  def pull(self):\n",
        "    # draw a 1 with probability p\n",
        "    return np.random.random() < self.p\n",
        "\n",
        "  def update(self, x):\n",
        "    self.N +=  1 # NUMBER OF SAMPLE COLLECTED\n",
        "    #self.p_estimate = ((self.N - 1)* self.p_estimate    + x)/ self.N\n",
        "    self.p_estimate = self.p_estimate + (( x - self.p_estimate )/ self.N)\n",
        "\n",
        "\n",
        "  def update_EPS(self, EPS):\n",
        "      self.EPS = 0*(self.EPS *0.75**0.5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B-XdBIBfLDYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment():\n",
        "  bandits = [BanditArm(p,EPS) for p in BANDIT_PROBABILITIES]\n",
        "\n",
        "  rewards = np.zeros(NUM_TRIALS)\n",
        "  num_times_explored = 0\n",
        "  num_times_exploited = 0\n",
        "  num_optimal = 0\n",
        "  optimal_j = np.argmax([b.p for b in bandits]) # WILL NOT E KNOWN IN REAL LIFE\n",
        "  print(\"optimal j:\", optimal_j)\n",
        "\n",
        "  for i in range(NUM_TRIALS):\n",
        "\n",
        "    # use epsilon-greedy to select the next bandit\n",
        "    if np.random.random() < EPS:\n",
        "      num_times_explored += 1\n",
        "      j = np.random.randint(len(bandits))\n",
        "\n",
        "    else:\n",
        "      num_times_exploited += 1\n",
        "      j = np.argmax([b.p_estimate for b in bandits])\n",
        "\n",
        "    # Will not be known in real life\n",
        "    if j == optimal_j:\n",
        "      num_optimal += 1\n",
        "\n",
        "    # pull the arm for the bandit with the largest sample\n",
        "    x = bandits[j].pull()\n",
        "\n",
        "    # update rewards log\n",
        "    rewards[i] = x\n",
        "\n",
        "    # update the distribution for the bandit whose arm we just pulled\n",
        "    bandits[j].update(x)\n",
        "\n",
        "      # update the distribution for the bandit whose arm we just pulled\n",
        "    bandits[j].update_EPS(EPS)\n",
        "     \n",
        "\n",
        " \n",
        "\n",
        "  # print mean estimates for each bandit\n",
        "  for b in bandits:\n",
        "    print(\"mean estimate:\", b.p_estimate)\n",
        "\n",
        "  # print total reward\n",
        "  print(\"total reward earned:\", rewards.sum())\n",
        "  print(\"overall win rate:\", rewards.sum() / NUM_TRIALS)\n",
        "  print(\"num_times_explored:\", num_times_explored)\n",
        "  print(\"num_times_exploited:\", num_times_exploited)\n",
        "  #print(\"num times selected optimal bandit:\", num_optimal)\n",
        "\n",
        "  # plot the results\n",
        "  cumulative_rewards = np.cumsum(rewards)\n",
        "  win_rates = cumulative_rewards / (np.arange(NUM_TRIALS) + 1)\n",
        "  plt.plot(win_rates)\n",
        "  #plt.plot(np.ones(NUM_TRIALS)*np.max(BANDIT_PROBABILITIES))\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  experiment() \n",
        "\n"
      ],
      "metadata": {
        "id": "XGW4bzDXLQ7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}